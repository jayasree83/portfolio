<!DOCTYPE HTML>

<html>
	<head>
		<title>Jayasree's Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Projects</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">About Me</a></li>
							<li><a href="generic.html">Experience</a></li>
							<li class="active"><a href="elements.html">Projects</a></li>
							<li><a href="certifications.html">Certifications</a></li>
							<li><a href="activities.html">Contributions</a></li>
							
							
						</ul>
						<ul class="icons">
							<li><a href="https://www.linkedin.com/in/jayasree-p/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
							<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								
								<!-- Project stuff -->
								
									<h2>Workflow Orchestration with Airflow and AWS</h2>
									<p>The goal of this project is to build an <b>end-to-end data pipeline</b> that securely connects, manages, streamlines, and analyzes data generated from the Rapid API. The pipeline extracts data for a given location in JSON format, transforms it, and stores it in AWS for further analysis. The entire workflow is orchestrated in Airflow which is set up in <b>virtual environment on EC2 instance</b>. This project repository contains Airflow <b>Directed Acyclic Graph (DAG)</b> designed to automate the process of fetching property data from the Rapid API, processing it, and loading it into Amazon <i>S3</i> and <i>Redshift</i> for further analysis. The DAG defines an end-to-end workflow, starting from extracting data via API requests to performing checks and loading the data into AWS S3 and Redshift for analytical purposes.</p>
									Project can be found <a href="https://github.com/jayasree83/Workflow_Orchestration.git">here</a>.</p>
									<hr />

									<header>
										<h2>Zillow Data Analytics - E2E pipeline on AWS with Glue ETL </h2>
										<p>This project implements an end-to-end data pipeline for processing and analyzing property listings from the Zillow API. Hosted on AWS, it automates data ingestion, processing, transformation, and visualization.</p>
										<p>Services Used- <b>AWS Lambda</b> for ingestion and transformation, <b>S3</b> for storage, <b>Glue</b> for ETL, <b>Athena for analysis</b>, <b>Quicksight</b> for visualizing and reporting, <b>Cloudwatch</b> for monitoring and <b>IAM</b> for access control </p>
										Project can be found <a href="https://github.com/jayasree83/Zillow-Data-Analytics.git">here</a>.</p>
									</header>
									<hr/>
									
									<header>
										<h2>Youtube - Scraped Data Analysis</h2>
										<p>This project explores the YouTube presence of colleges in the <b>Kansas and Missouri</b> area by leveraging the <b>YouTube Data API v3</b>. It involved collecting channel and video statistics such as subscriber counts, views, likes, and publishing trends. Insights were generated to compare engagement levels and content performance across institutions. Visualizations, including bar plots and trend charts, were created to showcase the findings. This project demonstrates skills in API integration, data processing, and visualization, providing actionable insights into digital engagement.</p>
										Project can be found <a href="https://github.com/jayasree83/Youtube_Scraped-Data-Analysis.git">here</a>.</p>
									</header>
									<hr/>

									<header>
										<h2>Sentiment Analysis - Airline Reviews</h2>
										<p>This project analyzes airline reviews to identify customer sentiments (positive, neutral, negative) and provide insights into customer satisfaction across various airlines. By leveraging sentiment analysis and visualizations, the project highlights key areas of improvement and compares top airlines based on features like service, food, and entertainment.</p>
										<p>Key highlights include sentiment classification using <b>NLTK, feature extraction,</b> and visualizations such as <b>sentiment distributions, performance comparisons, and trend analysis</b>. This project showcases skills in data preprocessing, natural language processing, and exploratory data analysis with tools like Matplotlib, Seaborn, and Scikit-learn.</p>
										Project can be found <a href="https://github.com/jayasree83/Sentiment-Analysis_AirlineReviews.git">here</a>.</p>
									</header>
									<hr/>

									<header>
										<h2>Covid-19 Data Exploration & Analysis</h2>
										<p>This project deals with the Analysis of global COVID data to assess infection rates, identify countries with high infection rate, likelihood of deaths, providing insights.</p>
										Advanced SQL techniques including <b>Joins, CTEs, window functions</b> etc. are used to analyze raw COVID data set. Finally, â€¢	Developed a comprehensive report detailing the global vaccination rates, continents with highest deaths per population ratio, countries with highest number of infections etc.</p>
										Project can be found <a href="https://github.com/jayasree83/Data-Exploration-and-Analysis.git">here</a>.</p>
									</header>
									<hr/>

									

											<h5>connect:</h3>
											<ul class="icons">
												<li><a href="https://www.linkedin.com/in/jayasree-p/" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
												<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
												
											</ul>
											
										</div>
									</div>
									

									

				

				

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>